{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivani-tutika/LLM-Growth-Training/blob/main/When_to_grow_shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Best models of pre-trained methods\n",
        "\n",
        "Comperative Survey:\n",
        "\n",
        "Wiki - 2\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Stacking|-|-|-|-|-|\n",
        "|LiGO Depth only|-|-|-|-|-|\n",
        "|CrossLiGO depth only|-|-|-|-|-|\n",
        "|StackLiGO depth only|-|-|-|-|-|\n",
        "\n",
        "\n",
        "Wiki - 103\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Stacking|-|-|-|-|-|\n",
        "|LiGO Depth only|-|-|-|-|-|\n",
        "|CrossLiGO depth only|-|-|-|-|-|\n",
        "|StackLiGO depth only|-|-|-|-|-|\n",
        "\n",
        "\n",
        "Shakespeare\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Stacking|-|-|-|-|-|\n",
        "|LiGO Depth only|-|-|-|-|-|\n",
        "|CrossLiGO depth only|-|-|-|-|-|\n",
        "|StackLiGO depth only|-|-|-|-|-|\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\"When to grow policy\"\n",
        "\n",
        "Wiki-2\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Periodic|-|-|-|-|-|\n",
        "|Convergence|-|-|-|-|-|\n",
        "|LipGrow|-|-|-|-|-|\n",
        "|FRAWGrow|-|-|-|-|-|\n",
        "\n",
        "Wiki-103\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Periodic|-|-|-|-|-|\n",
        "|Convergence|-|-|-|-|-|\n",
        "|LipGrow|-|-|-|-|-|\n",
        "|FRAWGrow|-|-|-|-|-|\n",
        "\n",
        "Shakespeare\n",
        "\n",
        "| Model | Category | Validation Loss | Training FLOPs | Memory | Time |\n",
        "|-|-|-|-|-|-|\n",
        "|Periodic|-|-|-|-|-|\n",
        "|Convergence|-|-|-|-|-|\n",
        "|LipGrow|-|-|-|-|-|\n",
        "|FRAWGrow|-|-|-|-|-|"
      ],
      "metadata": {
        "id": "LOhG0ziC8fkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "Hj_jn9Hn3yNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r92NvRI5ey3G",
        "outputId": "ad9a7306-9b9d-44cb-d16c-5269df4561bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (2.6.0)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nt0469.students\\.conda\\envs\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp39-cp39-win_amd64.whl (6.1 MB)\n",
            "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 6.1/6.1 MB 31.3 MB/s eta 0:00:00\n",
            "Downloading https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp39-cp39-win_amd64.whl (2496.0 MB)\n",
            "   ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.5 GB 124.1 MB/s eta 0:00:20\n",
            "    --------------------------------------- 0.0/2.5 GB 122.0 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 0.1/2.5 GB 120.0 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 0.1/2.5 GB 119.7 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 0.1/2.5 GB 118.5 MB/s eta 0:00:21\n",
            "   -- ------------------------------------- 0.1/2.5 GB 114.6 MB/s eta 0:00:21\n",
            "   -- ------------------------------------- 0.2/2.5 GB 113.0 MB/s eta 0:00:21\n",
            "   -- ------------------------------------- 0.2/2.5 GB 112.8 MB/s eta 0:00:21\n",
            "   --- ------------------------------------ 0.2/2.5 GB 111.0 MB/s eta 0:00:21\n",
            "   --- ------------------------------------ 0.2/2.5 GB 110.4 MB/s eta 0:00:21\n",
            "   --- ------------------------------------ 0.2/2.5 GB 110.5 MB/s eta 0:00:21\n",
            "   ---- ----------------------------------- 0.3/2.5 GB 108.8 MB/s eta 0:00:21\n",
            "   ---- ----------------------------------- 0.3/2.5 GB 108.1 MB/s eta 0:00:21\n",
            "   ---- ----------------------------------- 0.3/2.5 GB 107.4 MB/s eta 0:00:21\n",
            "   ----- ---------------------------------- 0.3/2.5 GB 106.8 MB/s eta 0:00:21\n",
            "   ----- ---------------------------------- 0.4/2.5 GB 106.8 MB/s eta 0:00:21\n",
            "   ------ --------------------------------- 0.4/2.5 GB 106.8 MB/s eta 0:00:20\n",
            "   ------ --------------------------------- 0.4/2.5 GB 108.2 MB/s eta 0:00:20\n",
            "   ------ --------------------------------- 0.4/2.5 GB 109.6 MB/s eta 0:00:19\n",
            "   ------- -------------------------------- 0.5/2.5 GB 109.6 MB/s eta 0:00:19\n",
            "   ------- -------------------------------- 0.5/2.5 GB 111.0 MB/s eta 0:00:19\n",
            "   -------- ------------------------------- 0.5/2.5 GB 112.4 MB/s eta 0:00:18\n",
            "   -------- ------------------------------- 0.5/2.5 GB 113.2 MB/s eta 0:00:18\n",
            "   -------- ------------------------------- 0.5/2.5 GB 114.8 MB/s eta 0:00:17\n",
            "   --------- ------------------------------ 0.6/2.5 GB 114.8 MB/s eta 0:00:17\n",
            "   --------- ------------------------------ 0.6/2.5 GB 116.4 MB/s eta 0:00:17\n",
            "   --------- ------------------------------ 0.6/2.5 GB 117.2 MB/s eta 0:00:16\n",
            "   ---------- ----------------------------- 0.6/2.5 GB 117.2 MB/s eta 0:00:16\n",
            "   ---------- ----------------------------- 0.7/2.5 GB 116.4 MB/s eta 0:00:16\n",
            "   ----------- ---------------------------- 0.7/2.5 GB 114.8 MB/s eta 0:00:16\n",
            "   ----------- ---------------------------- 0.7/2.5 GB 114.0 MB/s eta 0:00:16\n",
            "   ----------- ---------------------------- 0.7/2.5 GB 113.3 MB/s eta 0:00:16\n",
            "   ------------ --------------------------- 0.8/2.5 GB 112.5 MB/s eta 0:00:16\n",
            "   ------------ --------------------------- 0.8/2.5 GB 111.8 MB/s eta 0:00:16\n",
            "   ------------ --------------------------- 0.8/2.5 GB 110.3 MB/s eta 0:00:16\n",
            "   ------------- -------------------------- 0.8/2.5 GB 109.5 MB/s eta 0:00:16\n",
            "   ------------- -------------------------- 0.8/2.5 GB 107.4 MB/s eta 0:00:16\n",
            "   ------------- -------------------------- 0.9/2.5 GB 106.8 MB/s eta 0:00:16\n",
            "   -------------- ------------------------- 0.9/2.5 GB 105.4 MB/s eta 0:00:16\n",
            "   -------------- ------------------------- 0.9/2.5 GB 104.1 MB/s eta 0:00:16\n",
            "   -------------- ------------------------- 0.9/2.5 GB 103.5 MB/s eta 0:00:16\n",
            "   --------------- ------------------------ 0.9/2.5 GB 102.8 MB/s eta 0:00:16\n",
            "   --------------- ------------------------ 1.0/2.5 GB 102.8 MB/s eta 0:00:15\n",
            "   --------------- ------------------------ 1.0/2.5 GB 101.6 MB/s eta 0:00:15\n",
            "   ---------------- ----------------------- 1.0/2.5 GB 101.6 MB/s eta 0:00:15\n",
            "   ---------------- ----------------------- 1.0/2.5 GB 101.6 MB/s eta 0:00:15\n",
            "   ---------------- ----------------------- 1.0/2.5 GB 100.4 MB/s eta 0:00:15\n",
            "   ---------------- ----------------------- 1.0/2.5 GB 94.7 MB/s eta 0:00:16\n",
            "   ----------------- ---------------------- 1.1/2.5 GB 95.8 MB/s eta 0:00:15\n",
            "   ----------------- ---------------------- 1.1/2.5 GB 97.4 MB/s eta 0:00:15\n",
            "   ----------------- ---------------------- 1.1/2.5 GB 98.0 MB/s eta 0:00:15\n",
            "   ------------------ --------------------- 1.1/2.5 GB 98.0 MB/s eta 0:00:14\n",
            "   ------------------ --------------------- 1.2/2.5 GB 98.0 MB/s eta 0:00:14\n",
            "   ------------------ --------------------- 1.2/2.5 GB 98.6 MB/s eta 0:00:14\n",
            "   ------------------- -------------------- 1.2/2.5 GB 98.6 MB/s eta 0:00:14\n",
            "   ------------------- -------------------- 1.2/2.5 GB 98.6 MB/s eta 0:00:13\n",
            "   ------------------- -------------------- 1.2/2.5 GB 99.2 MB/s eta 0:00:13\n",
            "   -------------------- ------------------- 1.3/2.5 GB 99.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------- 1.3/2.5 GB 98.6 MB/s eta 0:00:13\n",
            "   -------------------- ------------------- 1.3/2.5 GB 105.4 MB/s eta 0:00:12\n",
            "   --------------------- ------------------ 1.3/2.5 GB 104.8 MB/s eta 0:00:12\n",
            "   --------------------- ------------------ 1.4/2.5 GB 102.8 MB/s eta 0:00:12\n",
            "   --------------------- ------------------ 1.4/2.5 GB 102.2 MB/s eta 0:00:11\n",
            "   ---------------------- ----------------- 1.4/2.5 GB 102.8 MB/s eta 0:00:11\n",
            "   ---------------------- ----------------- 1.4/2.5 GB 102.8 MB/s eta 0:00:11\n",
            "   ----------------------- ---------------- 1.4/2.5 GB 104.1 MB/s eta 0:00:11\n",
            "   ----------------------- ---------------- 1.5/2.5 GB 104.8 MB/s eta 0:00:10\n",
            "   ----------------------- ---------------- 1.5/2.5 GB 104.8 MB/s eta 0:00:10\n",
            "   ------------------------ --------------- 1.5/2.5 GB 105.4 MB/s eta 0:00:10\n",
            "   ------------------------ --------------- 1.5/2.5 GB 105.4 MB/s eta 0:00:10\n",
            "   ------------------------ --------------- 1.5/2.5 GB 104.8 MB/s eta 0:00:10\n",
            "   ------------------------- -------------- 1.6/2.5 GB 104.8 MB/s eta 0:00:09\n",
            "   ------------------------- -------------- 1.6/2.5 GB 105.4 MB/s eta 0:00:09\n",
            "   ------------------------- -------------- 1.6/2.5 GB 104.8 MB/s eta 0:00:09\n",
            "   -------------------------- ------------- 1.6/2.5 GB 104.8 MB/s eta 0:00:09\n",
            "   -------------------------- ------------- 1.7/2.5 GB 104.1 MB/s eta 0:00:09\n",
            "   -------------------------- ------------- 1.7/2.5 GB 104.1 MB/s eta 0:00:08\n",
            "   --------------------------- ------------ 1.7/2.5 GB 102.8 MB/s eta 0:00:08\n",
            "   --------------------------- ------------ 1.7/2.5 GB 102.2 MB/s eta 0:00:08\n",
            "   --------------------------- ------------ 1.7/2.5 GB 101.6 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 1.8/2.5 GB 102.2 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 1.8/2.5 GB 101.6 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 1.8/2.5 GB 102.2 MB/s eta 0:00:07\n",
            "   ----------------------------- ---------- 1.8/2.5 GB 102.2 MB/s eta 0:00:07\n",
            "   ----------------------------- ---------- 1.8/2.5 GB 102.9 MB/s eta 0:00:07\n",
            "   ----------------------------- ---------- 1.9/2.5 GB 104.1 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 1.9/2.5 GB 104.8 MB/s eta 0:00:06\n",
            "   ------------------------------ --------- 1.9/2.5 GB 104.8 MB/s eta 0:00:06\n",
            "   ------------------------------ --------- 1.9/2.5 GB 104.8 MB/s eta 0:00:06\n",
            "   ------------------------------- -------- 2.0/2.5 GB 106.1 MB/s eta 0:00:06\n",
            "   ------------------------------- -------- 2.0/2.5 GB 108.1 MB/s eta 0:00:05\n",
            "   -------------------------------- ------- 2.0/2.5 GB 110.3 MB/s eta 0:00:05\n",
            "   -------------------------------- ------- 2.0/2.5 GB 110.3 MB/s eta 0:00:05\n",
            "   -------------------------------- ------- 2.0/2.5 GB 110.3 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 2.1/2.5 GB 110.3 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 2.1/2.5 GB 110.3 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 2.1/2.5 GB 106.1 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 2.1/2.5 GB 101.0 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 2.1/2.5 GB 101.0 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 2.2/2.5 GB 99.8 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 2.2/2.5 GB 99.8 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 2.2/2.5 GB 99.8 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 2.2/2.5 GB 98.0 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 2.2/2.5 GB 96.9 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 2.3/2.5 GB 95.8 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 2.3/2.5 GB 94.7 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 2.3/2.5 GB 93.6 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 2.3/2.5 GB 93.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 2.3/2.5 GB 93.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 2.4/2.5 GB 93.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 2.4/2.5 GB 101.0 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 2.4/2.5 GB 102.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.4/2.5 GB 104.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 104.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 107.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.5/2.5 GB 108.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 GB 39.9 MB/s eta 0:00:00\n",
            "Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp39-cp39-win_amd64.whl (4.2 MB)\n",
            "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 4.2/4.2 MB 85.1 MB/s eta 0:00:00\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "Successfully installed torch-2.6.0+cu126 torchaudio-2.6.0+cu126 torchvision-0.21.0+cu126\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install calflops\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "tcxAYMIequeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622a1d14-d322-4256-dd2d-8603a30ff558",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:05:06.241759Z",
          "iopub.execute_input": "2025-02-16T17:05:06.242084Z",
          "iopub.status.idle": "2025-02-16T17:05:22.667774Z",
          "shell.execute_reply.started": "2025-02-16T17:05:06.242062Z",
          "shell.execute_reply": "2025-02-16T17:05:22.666651Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting calflops\n",
            "  Downloading calflops-0.3.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from calflops) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from calflops) (0.28.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from calflops) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->calflops) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->calflops) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->calflops) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.1.0->calflops)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1.0->calflops) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.1.0->calflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.1.0->calflops) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2025.1.31)\n",
            "Downloading calflops-0.3.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, calflops\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed calflops-0.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2Tokenizer, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "from calflops import calculate_flops\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "BljVUGon3-Pl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:05:22.669141Z",
          "iopub.execute_input": "2025-02-16T17:05:22.66939Z",
          "iopub.status.idle": "2025-02-16T17:05:28.27931Z",
          "shell.execute_reply.started": "2025-02-16T17:05:22.669366Z",
          "shell.execute_reply": "2025-02-16T17:05:28.278407Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ],
      "metadata": {
        "id": "D3Wp-_KgrHLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LiGO_bool = True\n",
        "emb_size = 256\n",
        "new_emb_size = 512\n",
        "block_size = 128\n",
        "multi_heads = 2\n",
        "batch_size = 16\n",
        "epochs = 3\n",
        "learning_rate = 3e-4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_small_layers = 4\n",
        "multi_heads = 2\n",
        "num_large_layers = 8"
      ],
      "metadata": {
        "id": "-qijUJI24EPv",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:05:28.281182Z",
          "iopub.execute_input": "2025-02-16T17:05:28.281471Z",
          "iopub.status.idle": "2025-02-16T17:05:28.358035Z",
          "shell.execute_reply.started": "2025-02-16T17:05:28.281435Z",
          "shell.execute_reply": "2025-02-16T17:05:28.357152Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "wPcPa_dTrEig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shakespeare"
      ],
      "metadata": {
        "id": "SNR7Z_yV4z02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load and process Shakespeare dataset\n",
        "with open('/content/shakespeare_dat.txt', 'r') as f:\n",
        "    dat = f.read()\n",
        "\n",
        "chars = sorted(list(set(dat)))\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda i: ''.join([itos[l] for l in i])\n",
        "\n",
        "# Convert text to tensor\n",
        "data = torch.tensor(encode(dat))\n",
        "\n",
        "# Train-test split (90% train, 10% validation)\n",
        "n = int(0.9 * len(data))\n",
        "shakespeare_train = data[:n]\n",
        "shakespeare_val = data[n:]\n"
      ],
      "metadata": {
        "id": "C4dqHzXQ4JmC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import numpy as np\n",
        "\n",
        "# # Load Shakespeare text from file\n",
        "# with open('/content/shakespeare_dat.txt', 'r') as f:\n",
        "#     dat = f.read()\n",
        "\n",
        "# # Character mappings\n",
        "# chars = sorted(list(set(dat)))\n",
        "# stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "# itos = {i: ch for i, ch in enumerate(chars)}\n",
        "# encode = lambda s: [stoi[c] for c in s]  # Convert text to integer list\n",
        "# decode = lambda i: ''.join([itos[l] for l in i])  # Convert int list to text\n",
        "\n",
        "\n",
        "# # Hyperparameters (Global)\n",
        "# block_size = 8\n",
        "# batch_size = 2048\n",
        "# val_batch_size = 2048\n",
        "# vocab_size = len(chars)\n",
        "# train_frac = 0.9  # Fraction for train-validation split\n",
        "\n",
        "\n",
        "# # Convert text data to tensor\n",
        "# data = torch.tensor(encode(dat), dtype=torch.long)\n",
        "\n",
        "# # Shuffle and Split Dataset\n",
        "# def shuffle_and_split(data, train_frac=0.9):\n",
        "#     n = int(train_frac * len(data))  # Split point\n",
        "#     indices = torch.randperm(len(data)).tolist()  # Shuffle indices\n",
        "#     train_data = data[indices[:n]]\n",
        "#     val_data = data[indices[n:]]\n",
        "#     return train_data, val_data\n",
        "\n",
        "# # Shuffle and split data\n",
        "# train_data, val_data = shuffle_and_split(data)\n",
        "\n",
        "# # Define a PyTorch Dataset\n",
        "# class ShakespeareDataset(Dataset):\n",
        "#     def __init__(self, data, block_size):\n",
        "#         self.data = data\n",
        "#         self.block_size = block_size\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) - self.block_size\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         x = self.data[idx:idx + self.block_size]\n",
        "#         y = self.data[idx + 1:idx + self.block_size + 1]\n",
        "#         return x, y\n",
        "\n",
        "# # Create DataLoader objects with custom variable names\n",
        "# shakespeare_train_dataset = ShakespeareDataset(train_data, block_size)\n",
        "# shakespeare_val_dataset = ShakespeareDataset(val_data, block_size)\n",
        "\n",
        "# shakespeare_train_loader = DataLoader(shakespeare_train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "# shakespeare_val_loader = DataLoader(shakespeare_val_dataset, batch_size=val_batch_size, shuffle=False, drop_last=True)\n"
      ],
      "metadata": {
        "id": "z15XoDEbU5lV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T16:51:47.564526Z",
          "iopub.execute_input": "2025-02-16T16:51:47.564847Z",
          "iopub.status.idle": "2025-02-16T16:51:47.595477Z",
          "shell.execute_reply.started": "2025-02-16T16:51:47.564819Z",
          "shell.execute_reply": "2025-02-16T16:51:47.594365Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Architecture"
      ],
      "metadata": {
        "id": "TtvXzO0ZuLL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LiGO_bool = True\n",
        "emb_size = 256\n",
        "new_emb_size = 512\n",
        "block_size = 128\n",
        "multi_heads = 2\n",
        "batch_size = 16\n",
        "epochs = 3\n",
        "learning_rate = 3e-4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_small_layers = 4\n",
        "multi_heads = 2\n",
        "num_large_layers = 8"
      ],
      "metadata": {
        "id": "7O4w2UUflJOq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic blocks"
      ],
      "metadata": {
        "id": "GcyDHoX_X1OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(torch.nn.Module):\n",
        "    def __init__(self, big=False):\n",
        "        super(AttentionHead, self).__init__()\n",
        "        self.k = torch.nn.Linear(new_emb_size if big else emb_size, new_emb_size if big else emb_size, bias=False)\n",
        "        self.q = torch.nn.Linear(new_emb_size if big else emb_size, new_emb_size if big else emb_size, bias=False)\n",
        "        self.v = torch.nn.Linear(new_emb_size if big else emb_size, new_emb_size if big else emb_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
        "    def forward(self, e):\n",
        "        keys = self.k(e)\n",
        "        queries = self.q(e)\n",
        "        values = self.v(e)\n",
        "        ret = keys @ queries.transpose(1, 2)*(1.0/math.sqrt(keys.size(-1)))\n",
        "        ret = torch.masked_fill(ret, self.tril==0, -torch.inf)\n",
        "        ret = torch.softmax(ret, 2)\n",
        "        ret = ret @ values\n",
        "        return ret"
      ],
      "metadata": {
        "id": "1Cb6ZkwhoaHC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.321331Z",
          "iopub.execute_input": "2025-02-16T17:25:58.321543Z",
          "iopub.status.idle": "2025-02-16T17:25:58.327627Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.321525Z",
          "shell.execute_reply": "2025-02-16T17:25:58.326882Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead(torch.nn.Module):\n",
        "    def __init__(self, big=False):\n",
        "        super(MultiHead, self).__init__()\n",
        "        self.head1 = AttentionHead(big)\n",
        "        self.head2 = AttentionHead(big)\n",
        "        self.mh_lin = torch.nn.Linear(multi_heads*(new_emb_size if big else emb_size), new_emb_size if big else emb_size, bias=False)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "    def forward(self, inp):\n",
        "        x1 = self.head1(inp)\n",
        "        x2 = self.head2(inp)\n",
        "        return self.mh_lin(self.drop(torch.cat([x1,x2], dim=2))).relu()"
      ],
      "metadata": {
        "id": "yMAuNR3hoaWi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.328442Z",
          "iopub.execute_input": "2025-02-16T17:25:58.328706Z",
          "iopub.status.idle": "2025-02-16T17:25:58.343628Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.328651Z",
          "shell.execute_reply": "2025-02-16T17:25:58.342824Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "UbQ_aSDmoala",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.345176Z",
          "iopub.execute_input": "2025-02-16T17:25:58.345369Z",
          "iopub.status.idle": "2025-02-16T17:25:58.35905Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.345352Z",
          "shell.execute_reply": "2025-02-16T17:25:58.358331Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(torch.nn.Module):\n",
        "    def __init__(self, big=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.multihead = MultiHead(big)\n",
        "        self.l_norm_1 = torch.nn.LayerNorm(new_emb_size if big else emb_size)\n",
        "        self.l_norm_2 = torch.nn.LayerNorm(new_emb_size if big else emb_size)\n",
        "        self.ffn = torch.nn.Linear(new_emb_size if big else emb_size, new_emb_size if big else emb_size)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "    def forward(self, inp):\n",
        "        m = self.l_norm_1(inp + self.multihead(inp))\n",
        "        m = self.l_norm_2(m + self.ffn(self.drop(m)).relu())\n",
        "        return m"
      ],
      "metadata": {
        "id": "59OUdvU5oa1q",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.359999Z",
          "iopub.execute_input": "2025-02-16T17:25:58.360274Z",
          "iopub.status.idle": "2025-02-16T17:25:58.372261Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.360245Z",
          "shell.execute_reply": "2025-02-16T17:25:58.371614Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Validation\n"
      ],
      "metadata": {
        "id": "QO7ivymhEP1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static methods"
      ],
      "metadata": {
        "id": "CocZb2PmdMtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(mdl, dataloader):\n",
        "    mdl.to(device)\n",
        "    mdl.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    torch.cuda.reset_peak_memory_stats(device)  # Reset memory stats\n",
        "\n",
        "    start_time = time.time()\n",
        "    for batch in dataloader:\n",
        "        inputs = batch[\"input_ids\"].squeeze(1).to(device)\n",
        "        outputs = mdl(inputs)\n",
        "        loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    val_time = time.time() - start_time\n",
        "    max_memory = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
        "\n",
        "    print(f\"Validation Time: {val_time:.2f}s, Max Memory Usage: {max_memory:.2f} MB\")\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "def get_cpu_memory():\n",
        "    \"\"\"Returns current CPU memory usage in MB.\"\"\"\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / (1024 ** 2)  # Convert bytes to MB\n",
        "\n",
        "def train(mdl, optim, epochs, train_dataloader, val_dataloader):\n",
        "    mdl.to(device)\n",
        "\n",
        "    train_losses_epoch = []\n",
        "    val_losses_epoch = []\n",
        "\n",
        "    train_times = []   # Training time per epoch\n",
        "    val_times = []     # Validation time per epoch\n",
        "    gpu_memory_usage = []  # GPU memory per epoch\n",
        "    cpu_memory_usage = []  # CPU memory per epoch\n",
        "    flops_per_epoch = []   # FLOPs per epoch\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        mdl.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "        total_flops = 0  # Track FLOPs for this epoch\n",
        "\n",
        "        torch.cuda.reset_peak_memory_stats(device)  # Reset GPU memory tracking\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            inputs = batch[\"input_ids\"].squeeze(1).to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = mdl(inputs).to(device)\n",
        "            loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Compute FLOPs for this batch\n",
        "            flops, _, _ = calculate_flops(model=mdl.to(device), kwargs={'inp': inputs},\n",
        "                                          print_detailed=False, print_results=False, output_as_string=False)\n",
        "            total_flops += flops  # Accumulate FLOPs\n",
        "\n",
        "            if num_batches % 100 == 0:\n",
        "                print(f\"{num_batches} processed\")\n",
        "\n",
        "        train_time = time.time() - start_time  # Epoch training time\n",
        "        train_times.append(train_time)\n",
        "\n",
        "        # Store memory usage\n",
        "        max_gpu_memory = torch.cuda.max_memory_allocated(device) / (1024 ** 2)  # MB\n",
        "        max_cpu_memory = get_cpu_memory()  # MB\n",
        "\n",
        "        # gpu_memory_usage.append(max_gpu_memory)\n",
        "        cpu_memory_usage.append(max_cpu_memory)\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        train_losses_epoch.append(avg_loss)\n",
        "\n",
        "        # Validate model and track validation time + memory usage\n",
        "        val_start_time = time.time()\n",
        "        val_loss, _ = validate(mdl, val_dataloader)\n",
        "        val_time = time.time() - val_start_time\n",
        "        val_times.append(val_time)\n",
        "\n",
        "        val_losses_epoch.append(val_loss)\n",
        "\n",
        "        # Convert FLOPs to TFLOPs (TeraFLOPs)\n",
        "        flops_per_epoch.append(total_flops / 1e12)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Train Time: {train_time:.2f}s, Val Time: {val_time:.2f}s, \"\n",
        "              f\"GPU Memory: MB, CPU Memory: {max_cpu_memory:.2f} MB, \"\n",
        "              f\"TFLOPs: {total_flops / 1e12:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"train_losses\": train_losses_epoch,\n",
        "        \"val_losses\": val_losses_epoch,\n",
        "        \"train_times\": train_times,\n",
        "        \"val_times\": val_times,\n",
        "        \"gpu_memory\": gpu_memory_usage,\n",
        "        \"cpu_memory\": cpu_memory_usage,\n",
        "        \"flops\": flops_per_epoch  # Returning FLOPs per epoch\n",
        "    }\n"
      ],
      "metadata": {
        "id": "tnK3b0kJETgI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.373099Z",
          "iopub.execute_input": "2025-02-16T17:25:58.373376Z",
          "iopub.status.idle": "2025-02-16T17:25:58.385794Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.373348Z",
          "shell.execute_reply": "2025-02-16T17:25:58.385016Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def validate(mdl, dataloader):\n",
        "    mdl.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    val_losses = []\n",
        "    for batch in dataloader:\n",
        "        inputs = batch[\"input_ids\"].squeeze(1).to(device)\n",
        "        outputs = mdl(inputs)\n",
        "        loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        if num_batches % 100 == 0:\n",
        "            val_losses.append(total_loss / num_batches)\n",
        "    return total_loss / num_batches, val_losses\n",
        "\n",
        "@torch.enable_grad()\n",
        "def train(mdl, optim, epochs, train_dataloader, val_dataloader):\n",
        "    # mdl.to(device)\n",
        "    train_losses = []\n",
        "    val_losses_epoch = []\n",
        "    for epoch in range(epochs):\n",
        "        mdl.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "        for batch in train_dataloader:\n",
        "            inputs = batch[\"input_ids\"].squeeze(1).to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = mdl(inputs)\n",
        "            loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            if num_batches % 100 == 0:\n",
        "                train_losses.append(total_loss / num_batches)\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        val_loss, val_losses = validate(mdl, val_dataloader)\n",
        "        val_losses_epoch.extend(val_losses)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses_epoch"
      ],
      "metadata": {
        "id": "nnxQwoRslqVp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T16:52:09.413556Z",
          "iopub.execute_input": "2025-02-16T16:52:09.413855Z",
          "iopub.status.idle": "2025-02-16T16:52:09.421877Z",
          "shell.execute_reply.started": "2025-02-16T16:52:09.413832Z",
          "shell.execute_reply": "2025-02-16T16:52:09.420929Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "torch.manual_seed(1337)\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size if split=='train' else val_batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(mdl):\n",
        "    mdl.eval()\n",
        "    vx, vy = get_batch('val')\n",
        "    out = mdl(vx.to(device))\n",
        "    return loss(out.view(-1, 65), vy.view(-1).to(device)).item()\n",
        "\n",
        "\n",
        "@torch.enable_grad()\n",
        "def train(mdl, optim, epochs):\n",
        "    ind = 0\n",
        "    train_curve = []\n",
        "    flops_per_epoch = []\n",
        "    train_loss_per_epoch = []\n",
        "    val_loss_per_epoch = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        mdl.train()\n",
        "        optim.zero_grad()\n",
        "        x, y = get_batch('train')\n",
        "        out = mdl(x.to(device))\n",
        "        l = loss(out.view(-1, 65), y.view(-1).to(device))\n",
        "        l.backward()\n",
        "        optim.step()\n",
        "        ind += 1\n",
        "\n",
        "        train_loss_per_epoch.append(l.item())\n",
        "\n",
        "        flops, macs, params = calculate_flops(model=mdl, kwargs={'inp': x.to(device)}, print_detailed=False, print_results=False, output_as_string=False)\n",
        "        flops_per_epoch.append(flops)\n",
        "        v = validate(mdl)\n",
        "        val_loss_per_epoch.append(v)\n",
        "\n",
        "        if ind%10 == 0:\n",
        "            v = validate(mdl)\n",
        "            if ind%100==0:\n",
        "                print(l.item())\n",
        "                print(f\"Validation: {v}\")\n",
        "            train_curve.append(v)\n",
        "\n",
        "\n",
        "    return train_curve, {\n",
        "        \"train_losses\": train_loss_per_epoch,\n",
        "        \"val_losses\": val_loss_per_epoch,\n",
        "        \"flops\": flops_per_epoch\n",
        "    }\n"
      ],
      "metadata": {
        "id": "6kp1s0RiVL9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "807ff344-5f26-4f63-8805-8866af6367d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d325991f8885>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic methods"
      ],
      "metadata": {
        "id": "qK5n1eSIdRUp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bm2wd2TodMGL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Periodic methods"
      ],
      "metadata": {
        "id": "da1uvfyTdVTD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCauDF-adMW5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convergence methods"
      ],
      "metadata": {
        "id": "gkFMGyv5dZ3v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zqefjhrdeDh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FRAWGrow"
      ],
      "metadata": {
        "id": "XN49_FZcddrz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vfmspcrdenL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "bhHzrgAh-5VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, layers_num):\n",
        "        super(Model, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.pe = PositionalEncoding(d_model=emb_size)\n",
        "\n",
        "        # Create a ModuleList to hold the blocks\n",
        "        self.blocks = nn.ModuleList([Block() for _ in range(layers_num)])\n",
        "\n",
        "        self.f_lin = nn.Linear(emb_size, vocab_size)\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        e = self.embedding(inp)\n",
        "        e = self.pe(e)\n",
        "\n",
        "        # Pass input through all blocks sequentially\n",
        "        for block in self.blocks:\n",
        "            e = block(e)\n",
        "\n",
        "        r = self.f_lin(self.drop(e))\n",
        "        return r"
      ],
      "metadata": {
        "id": "ovieku_uobEy",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.38667Z",
          "iopub.execute_input": "2025-02-16T17:25:58.386988Z",
          "iopub.status.idle": "2025-02-16T17:25:58.40126Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.38696Z",
          "shell.execute_reply": "2025-02-16T17:25:58.400591Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic model"
      ],
      "metadata": {
        "id": "vT_I4RzSDZO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "w3stSVoZkgmi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.401975Z",
          "iopub.execute_input": "2025-02-16T17:25:58.402222Z",
          "iopub.status.idle": "2025-02-16T17:25:58.415207Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.402193Z",
          "shell.execute_reply": "2025-02-16T17:25:58.414363Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "\n",
        "train(model, optimizer, 500)\n",
        "# metrics_basic_wiki103 = train(model, optimizer, 3, shakespeare_train_loader, shakespeare_val_loader)\n",
        "# metrics_basic_wiki2 = train(model, optimizer, 10, wikitext2_train_loader, wikitext2_val_loader)\n",
        "# metrics_basic_Shakespeare = train(model, optimizer, 10, shakespeare_train, shakespeare_val)"
      ],
      "metadata": {
        "id": "Nx7KxasnobSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b46cac3-4c74-449c-ffb5-df4c511d8142",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-16T17:25:58.416107Z",
          "iopub.execute_input": "2025-02-16T17:25:58.416392Z",
          "iopub.status.idle": "2025-02-16T20:41:45.816597Z",
          "shell.execute_reply.started": "2025-02-16T17:25:58.416365Z",
          "shell.execute_reply": "2025-02-16T20:41:45.815125Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.32271671295166\n",
            "Validation: 3.3193771839141846\n",
            "3.3074076175689697\n",
            "Validation: 3.315404176712036\n",
            "3.312060594558716\n",
            "Validation: 3.307648181915283\n",
            "3.3170957565307617\n",
            "Validation: 3.3158364295959473\n",
            "3.304936647415161\n",
            "Validation: 3.3132266998291016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.315258741378784,\n",
              " 3.3227009773254395,\n",
              " 3.3187713623046875,\n",
              " 3.302401065826416,\n",
              " 3.30961012840271,\n",
              " 3.297545909881592,\n",
              " 3.317373752593994,\n",
              " 3.3146419525146484,\n",
              " 3.307394504547119,\n",
              " 3.3193771839141846,\n",
              " 3.3155148029327393,\n",
              " 3.313724994659424,\n",
              " 3.306354284286499,\n",
              " 3.311169147491455,\n",
              " 3.307861328125,\n",
              " 3.309154510498047,\n",
              " 3.306323289871216,\n",
              " 3.3139724731445312,\n",
              " 3.3155057430267334,\n",
              " 3.315404176712036,\n",
              " 3.3113510608673096,\n",
              " 3.3050875663757324,\n",
              " 3.3035755157470703,\n",
              " 3.3067729473114014,\n",
              " 3.3030917644500732,\n",
              " 3.319765329360962,\n",
              " 3.312178373336792,\n",
              " 3.3066296577453613,\n",
              " 3.3167872428894043,\n",
              " 3.307648181915283,\n",
              " 3.2982420921325684,\n",
              " 3.305985450744629,\n",
              " 3.306915283203125,\n",
              " 3.302952527999878,\n",
              " 3.3126375675201416,\n",
              " 3.3144142627716064,\n",
              " 3.325624942779541,\n",
              " 3.3133952617645264,\n",
              " 3.3037314414978027,\n",
              " 3.3158364295959473,\n",
              " 3.324369192123413,\n",
              " 3.3016202449798584,\n",
              " 3.308969736099243,\n",
              " 3.3091368675231934,\n",
              " 3.311555862426758,\n",
              " 3.304093599319458,\n",
              " 3.312363624572754,\n",
              " 3.307833671569824,\n",
              " 3.31384015083313,\n",
              " 3.3132266998291016]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big Model"
      ],
      "metadata": {
        "id": "oahkKA0mY2eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigModel(torch.nn.Module):\n",
        "    def __init__(self, big=False):\n",
        "        super(BigModel, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, new_emb_size if big else emb_size)\n",
        "        self.pe = PositionalEncoding(d_model= new_emb_size if big else emb_size)\n",
        "        self.block1 = Block(big=big)\n",
        "        self.block2 = Block(big=big)\n",
        "        self.block3 = Block(big=big)\n",
        "        self.block4 = Block(big=big)\n",
        "        self.block5 = Block(big=big)\n",
        "        self.block6 = Block(big=big)\n",
        "        self.block7 = Block(big=big)\n",
        "        self.block8 = Block(big=big)\n",
        "        self.f_lin = torch.nn.Linear(new_emb_size if big else emb_size, vocab_size)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "    def forward(self, inp):\n",
        "        e = self.embedding(inp)\n",
        "        e = self.pe(e)\n",
        "        m = self.block1(e)\n",
        "        m = self.block2(m)\n",
        "        m = self.block3(m)\n",
        "        m = self.block4(m)\n",
        "        m = self.block5(m)\n",
        "        m = self.block6(m)\n",
        "        m = self.block7(m)\n",
        "        m = self.block8(m)\n",
        "        r = self.f_lin(self.drop(m))\n",
        "        return r"
      ],
      "metadata": {
        "id": "Xw6wYDBBY4jF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fused transformer Architecture"
      ],
      "metadata": {
        "id": "A_218uBWSEL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_params = torch.empty((0,emb_size*emb_size)).to(device)\n",
        "q_params = torch.empty((0,emb_size*emb_size)).to(device)\n",
        "v_params = torch.empty((0,emb_size*emb_size)).to(device)\n",
        "lin_params = torch.empty((0, 2*emb_size*emb_size)).to(device)\n",
        "ffn_w_params = torch.empty((0, emb_size*emb_size)).to(device)\n",
        "ffn_b_params = torch.empty((0, emb_size)).to(device)\n",
        "l_norm_w_params = torch.empty((0, emb_size)).to(device)\n",
        "l_norm_b_params = torch.empty((0, emb_size)).to(device)\n",
        "for i in model.state_dict():\n",
        "    if '.k.' in i:\n",
        "        k_params = torch.cat((k_params, model.state_dict()[i].flatten().view(1,-1)), dim=0)\n",
        "    elif '.q.' in i:\n",
        "        q_params = torch.cat((q_params, model.state_dict()[i].flatten().view(1,-1)), dim=0)\n",
        "    elif '.v.' in i:\n",
        "        v_params = torch.cat((v_params, model.state_dict()[i].flatten().view(1,-1)), dim=0)\n",
        "    elif '.mh_lin' in i:\n",
        "        lin_params = torch.cat((lin_params, model.state_dict()[i].flatten().view(1,-1)), dim = 0)\n",
        "    elif 'ffn' in i and 'weight' in i:\n",
        "        ffn_w_params = torch.cat((ffn_w_params, model.state_dict()[i].flatten().view(1,-1)), dim = 0)\n",
        "    elif 'ffn' in i and 'bias' in i:\n",
        "        ffn_b_params = torch.cat((ffn_b_params, model.state_dict()[i].flatten().view(1,-1)), dim = 0)\n",
        "    elif 'l_norm' in i and 'weight' in i:\n",
        "        l_norm_w_params = torch.cat((l_norm_w_params, model.state_dict()[i].flatten().view(1,-1)), dim = 0)\n",
        "    elif 'l_norm' in i and 'bias' in i:\n",
        "        l_norm_b_params = torch.cat((l_norm_b_params, model.state_dict()[i].flatten().view(1,-1)), dim = 0)\n"
      ],
      "metadata": {
        "id": "XgC7pjGNYFu7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedEmbedding(torch.nn.Module):\n",
        "    def __init__(self, emb_params, static=True, width=False, width_static=True):\n",
        "        super(FusedEmbedding, self).__init__()\n",
        "        self.static = static\n",
        "        self.width_static = width_static\n",
        "        self.width=width\n",
        "        if static:\n",
        "            if width:\n",
        "                if width_static:\n",
        "                    self.emb_params = torch.cat((emb_params, emb_params)).view(vocab_size, -1)\n",
        "                else:\n",
        "                    self.emb_params = emb_params.view(vocab_size, -1)\n",
        "                    self.width_w = torch.nn.Linear(emb_size, new_emb_size, bias=False)\n",
        "            else:\n",
        "                self.emb_params = emb_params.view(vocab_size, -1)\n",
        "        else:\n",
        "            self.width = width\n",
        "            self.emb_params = emb_params\n",
        "    def forward(self, inp):\n",
        "        emb = self.emb_params\n",
        "        if self.static:\n",
        "            if self.width:\n",
        "                if self.width_static:\n",
        "                    return torch.nn.functional.embedding(inp, emb)\n",
        "                return torch.nn.functional.embedding(inp, self.width_w(emb))\n",
        "        emb = emb.view(vocab_size, -1)\n",
        "        return torch.nn.functional.embedding(inp, emb)"
      ],
      "metadata": {
        "id": "m095g9UGYGPQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedLin(torch.nn.Module):\n",
        "    def __init__(self, num_layers, in_dim, out_dim, small_params_w, small_params_b = None, static = False, width_static=True, width=False, old_in_dim = emb_size, old_out_dim = emb_size):\n",
        "        super( FusedLin, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.static = static\n",
        "        self.width = width\n",
        "        self.old_in_dim = old_in_dim\n",
        "        self.old_out_dim = old_out_dim\n",
        "        self.width_static = width_static\n",
        "        self.final = True if out_dim == vocab_size else False\n",
        "        if not self.final and static:\n",
        "            if width:\n",
        "                if width_static:\n",
        "                    self.register_buffer('small_params_w', torch.kron(torch.eye(int(out_dim/old_out_dim), int(in_dim/old_in_dim)).to(device), small_params_w).view(out_dim, in_dim))\n",
        "                    if small_params_b is not None:\n",
        "                        if old_out_dim == out_dim:\n",
        "                            self.register_buffer('small_params_b', small_params_b)\n",
        "                        else:\n",
        "                            self.register_buffer('small_params_b', torch.cat((small_params_b, small_params_b)))\n",
        "                    else:\n",
        "                        self.small_params_b = None\n",
        "                else:\n",
        "                    self.register_buffer('small_params_w', small_params_w)\n",
        "                    self.width_wa = torch.nn.Linear(old_out_dim, out_dim, bias=False) if width else None\n",
        "                    self.width_wb = torch.nn.Linear(old_in_dim, in_dim, bias=False) if width else None\n",
        "                    if small_params_b is not None:\n",
        "                        self.register_buffer('small_params_b', small_params_b)\n",
        "                    else:\n",
        "                        self.small_params_b = None\n",
        "                    self.width_b = torch.nn.Linear(old_out_dim, out_dim, bias=False) if width and small_params_b is not None else None\n",
        "            else:\n",
        "                self.register_buffer('small_params_w', small_params_w.view(out_dim, in_dim))\n",
        "                if small_params_b is not None:\n",
        "                    self.register_buffer('small_params_b', small_params_b)\n",
        "                else:\n",
        "                    self.small_params_b = None\n",
        "        else:\n",
        "            self.width_wa = torch.nn.Linear(old_out_dim, out_dim, bias=False) if width and not self.final else None\n",
        "            self.width_wb = torch.nn.Linear(old_in_dim, in_dim, bias=False) if width else None\n",
        "            self.width_b = torch.nn.Linear(old_out_dim, out_dim, bias=False) if width and small_params_b is not None and not self.final else None\n",
        "            if not self.final:\n",
        "                self.lin_w = torch.nn.Parameter(torch.rand(num_layers))\n",
        "                if small_params_b is not None:\n",
        "                    self.lin_b = torch.nn.Parameter(torch.rand(num_layers))\n",
        "            self.register_buffer('small_params_w', small_params_w)\n",
        "            if small_params_b is not None:\n",
        "                self.register_buffer('small_params_b', small_params_b)\n",
        "            else:\n",
        "                self.small_params_b = None\n",
        "    def forward(self, inp):\n",
        "        if self.static and not self.final:\n",
        "            weight=self.small_params_w\n",
        "            bias=self.small_params_b\n",
        "            if not self.width_static:\n",
        "                weight = self.width_wb(weight.view(self.old_out_dim, self.old_in_dim))\n",
        "                weight = self.width_wa(weight.T).T\n",
        "                if bias is not None:\n",
        "                    bias = self.width_b(bias)\n",
        "            return torch.nn.functional.linear(inp, weight=weight, bias=bias)\n",
        "        if self.final:\n",
        "            weight = self.small_params_w\n",
        "            bias = self.small_params_b\n",
        "        else:\n",
        "            weight = self.small_params_w.T @ self.lin_w\n",
        "            bias = None\n",
        "            if self.small_params_b is not None:\n",
        "                bias = self.small_params_b.T@self.lin_b\n",
        "        if self.width:\n",
        "            if not self.final:\n",
        "                weight = self.width_wb(weight.view(self.old_out_dim, self.old_in_dim))\n",
        "                weight = self.width_wa(weight.T).T\n",
        "            else:\n",
        "                weight = self.width_wb(weight.view(self.old_out_dim, self.old_in_dim))\n",
        "        if self.width_b is not None:\n",
        "            bias = self.width_b(bias)\n",
        "        weight = weight.view(self.out_dim, self.in_dim)\n",
        "        return torch.nn.functional.linear(inp, weight, bias = bias)"
      ],
      "metadata": {
        "id": "VGOoEYjKYGrB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedNorm(torch.nn.Module):\n",
        "    def __init__(self, num_layers, small_params_w, small_params_b, static=False, width_static = True, width=False):\n",
        "        super(FusedNorm, self).__init__()\n",
        "        self.static = static\n",
        "        self.width = width\n",
        "        self.width_static = width_static\n",
        "        if not static:\n",
        "            self.register_buffer('small_params_w', small_params_w)\n",
        "            self.register_buffer('small_params_b', small_params_b)\n",
        "            self.lin_w = torch.nn.Parameter(torch.randn(num_layers))\n",
        "            self.lin_b = torch.nn.Parameter(torch.randn(num_layers))\n",
        "            if width:\n",
        "                self.width_w = torch.nn.Linear(emb_size, new_emb_size, bias=False)\n",
        "                self.width_b = torch.nn.Linear(emb_size, new_emb_size, bias=False)\n",
        "        else:\n",
        "            if width:\n",
        "                if width_static:\n",
        "                    self.register_buffer('small_params_w', torch.cat((small_params_w, small_params_w)))\n",
        "                    self.register_buffer('small_params_b', torch.cat((small_params_b, small_params_b)))\n",
        "                else:\n",
        "                    self.register_buffer('small_params_w', small_params_w)\n",
        "                    self.register_buffer('small_params_b', small_params_b)\n",
        "                    self.width_w = torch.nn.Linear(emb_size, new_emb_size, bias=False)\n",
        "                    self.width_b = torch.nn.Linear(emb_size, new_emb_size, bias=False)\n",
        "            else:\n",
        "                self.register_buffer('small_params_w', small_params_w)\n",
        "                self.register_buffer('small_params_b', small_params_b)\n",
        "    def forward(self, inp):\n",
        "        if self.static:\n",
        "            weight = self.small_params_w\n",
        "            bias = self.small_params_b\n",
        "            e_s = emb_size if not self.width else new_emb_size\n",
        "            if not self.width_static:\n",
        "                weight = self.width_w(weight)\n",
        "                bias = self.width_b(bias)\n",
        "            return torch.nn.functional.layer_norm(inp, tuple([e_s]), weight=weight, bias=bias)\n",
        "        weight = self.small_params_w.T @ self.lin_w\n",
        "        bias = self.small_params_b.T @ self.lin_b\n",
        "        if self.width:\n",
        "            weight = self.width_w(weight)\n",
        "            bias = self.width_b(bias)\n",
        "        e_s = emb_size if not self.width else new_emb_size\n",
        "        return torch.nn.functional.layer_norm(inp, tuple([e_s]), weight=weight, bias=bias)\n"
      ],
      "metadata": {
        "id": "d3hx3ID4YQOO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedAttentionHead(torch.nn.Module):\n",
        "    def __init__(self, static=False, layerNum=None, width=False, width_static = True):\n",
        "        super( FusedAttentionHead, self).__init__()\n",
        "        self.static = static\n",
        "        self.width_static = width_static\n",
        "        if not static:\n",
        "            self.k = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, k_params, width=width, width_static=width_static)\n",
        "            self.q = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, q_params, width=width, width_static=width_static)\n",
        "            self.v = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, v_params, width=width, width_static=width_static)\n",
        "        else:\n",
        "            self.k = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, k_params[layerNum], static=True, width=width, width_static=width_static)\n",
        "            self.q = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, q_params[layerNum], static=True, width=width, width_static=width_static)\n",
        "            self.v = FusedLin(num_small_layers*multi_heads, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, v_params[layerNum], static=True, width=width, width_static=width_static)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
        "    def forward(self, e):\n",
        "        keys = self.k(e)\n",
        "        queries = self.q(e)\n",
        "        values = self.v(e)\n",
        "        ret = keys @ queries.transpose(1, 2)*(1.0/math.sqrt(keys.size(-1)))\n",
        "        ret = torch.masked_fill(ret, self.tril==0, -torch.inf)\n",
        "        ret = torch.softmax(ret, 2)\n",
        "        ret = ret @ values\n",
        "        return ret"
      ],
      "metadata": {
        "id": "rRoVLVE7YQg8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedMultiHead(torch.nn.Module):\n",
        "    def __init__(self, static=False, layerNum=None, width=False, width_static = True):\n",
        "        super( FusedMultiHead, self).__init__()\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        self.width_static = width_static\n",
        "        if not static:\n",
        "            self.head1 = FusedAttentionHead(width=width, width_static=width_static)\n",
        "            self.head2 = FusedAttentionHead(width=width, width_static=width_static)\n",
        "            self.mh_lin = FusedLin(num_small_layers, multi_heads*(emb_size if not width else new_emb_size), emb_size if not width else new_emb_size, lin_params, width=width, old_in_dim=multi_heads*emb_size , old_out_dim=emb_size, width_static=width_static)\n",
        "        else:\n",
        "            self.head1 = FusedAttentionHead(static=True, layerNum=2*layerNum, width=width, width_static=width_static)\n",
        "            self.head2 = FusedAttentionHead(static=True, layerNum=2*layerNum+1, width=width, width_static=width_static)\n",
        "            self.mh_lin = FusedLin(num_small_layers, multi_heads*(emb_size if not width else new_emb_size), emb_size if not width else new_emb_size, lin_params[layerNum], static=True, width=width, width_static=width_static, old_in_dim=multi_heads*emb_size, old_out_dim=emb_size)\n",
        "    def forward(self, inp):\n",
        "        x1 = self.head1(inp)\n",
        "        x2 = self.head2(inp)\n",
        "        return self.mh_lin(self.drop(torch.cat([x1,x2], dim=2))).relu()"
      ],
      "metadata": {
        "id": "1v8YFEKdYQ0E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class FusedBlock(torch.nn.Module):\n",
        "    def __init__(self, static=False, layerNum=None, width=False, width_static = True):\n",
        "        super(FusedBlock, self).__init__()\n",
        "        self.static = static\n",
        "        self.width_static = width_static\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        if not static:\n",
        "            self.multiHead = FusedMultiHead(width=width, width_static=width_static)\n",
        "            self.norm_1 = FusedNorm(num_small_layers*2, l_norm_w_params, l_norm_b_params, width=width, width_static=width_static)\n",
        "            self.norm_2 = FusedNorm(num_small_layers*2, l_norm_w_params, l_norm_b_params, width=width, width_static=width_static)\n",
        "            self.ffn = FusedLin(num_small_layers, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, ffn_w_params, ffn_b_params, width=width, width_static=width_static)\n",
        "        else:\n",
        "            self.multiHead = FusedMultiHead(static=True, layerNum=layerNum, width=width, width_static=width_static)\n",
        "            self.norm_1 = FusedNorm(num_small_layers*2, l_norm_w_params[layerNum*2], l_norm_b_params[layerNum*2], static=True, width=width, width_static=width_static)\n",
        "            self.norm_2 = FusedNorm(num_small_layers*2, l_norm_w_params[layerNum*2+1], l_norm_b_params[layerNum*2+1], static=True, width=width, width_static=width_static)\n",
        "            self.ffn = FusedLin(num_small_layers, emb_size if not width else new_emb_size, emb_size if not width else new_emb_size, ffn_w_params[layerNum], ffn_b_params[layerNum], static=True, width=width, width_static=width_static)\n",
        "    def forward(self, inp):\n",
        "        m = self.norm_1(inp + self.multiHead(inp))\n",
        "        m = self.norm_2(m + self.ffn(self.drop(m)).relu())\n",
        "        return m\n"
      ],
      "metadata": {
        "id": "UHrk8bLaYZk-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LiGO & CrossLiGO"
      ],
      "metadata": {
        "id": "blY7UQ3qYc2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackLiGO(torch.nn.Module):\n",
        "    def __init__(self, width=False) -> None:\n",
        "        super(StackLiGO, self).__init__()\n",
        "        self.emb = FusedEmbedding(emb_params=model.embedding.weight.flatten().clone(), width=width, static=True)\n",
        "        self.pe = PositionalEncoding(d_model=new_emb_size if width else emb_size)\n",
        "        self.block1 = FusedBlock(static=True, layerNum=0, width=width)\n",
        "        self.block2 = FusedBlock(static=True, layerNum=1, width=width)\n",
        "        self.block3 = FusedBlock(static=True, layerNum=2, width=width)\n",
        "        self.block4 = FusedBlock(static=True, layerNum=3, width=width)\n",
        "        self.block5 = FusedBlock(width=width)\n",
        "        self.block6 = FusedBlock(width=width)\n",
        "        self.block7 = FusedBlock(width=width)\n",
        "        self.block8 = FusedBlock(width=width)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        self.f_lin = FusedLin(1, in_dim=emb_size if not width else new_emb_size, out_dim=vocab_size, static=True, small_params_w= model.f_lin.weight.flatten().clone(), small_params_b=model.f_lin.bias.clone(), width=width, old_in_dim=emb_size, old_out_dim=vocab_size)\n",
        "    def forward(self, inp):\n",
        "        e = self.emb(inp)\n",
        "        e = self.pe(e)\n",
        "        m = self.block1(e)\n",
        "        m = self.block2(m)\n",
        "        m = self.block3(m)\n",
        "        m = self.block4(m)\n",
        "        m = self.block5(m)\n",
        "        m = self.block6(m)\n",
        "        m = self.block7(m)\n",
        "        m = self.block8(m)\n",
        "        return self.f_lin(self.drop(m))"
      ],
      "metadata": {
        "id": "1SJukbD7YXyk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class StackLiGOv2(torch.nn.Module):\n",
        "    def __init__(self, width=False) -> None:\n",
        "        super(StackLiGOv2, self).__init__()\n",
        "        self.emb = FusedEmbedding(emb_params=model.embedding.weight.flatten().clone(), width=width, static=True, width_static=False)\n",
        "        self.pe = PositionalEncoding(d_model=new_emb_size if width else emb_size)\n",
        "        self.block1 = FusedBlock(static=True, layerNum=0, width=width, width_static=False)\n",
        "        self.block2 = FusedBlock(static=True, layerNum=1, width=width, width_static=False)\n",
        "        self.block3 = FusedBlock(static=True, layerNum=2, width=width, width_static=False)\n",
        "        self.block4 = FusedBlock(static=True, layerNum=3, width=width, width_static=False)\n",
        "        self.block5 = FusedBlock(width=width)\n",
        "        self.block6 = FusedBlock(width=width)\n",
        "        self.block7 = FusedBlock(width=width)\n",
        "        self.block8 = FusedBlock(width=width)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        self.f_lin = FusedLin(1, in_dim=emb_size if not width else new_emb_size, out_dim=vocab_size, static=True, small_params_w= model.f_lin.weight.flatten().clone(), small_params_b=model.f_lin.bias.clone(), width=width, old_in_dim=emb_size, old_out_dim=vocab_size)\n",
        "    def forward(self, inp):\n",
        "        e = self.emb(inp)\n",
        "        e = self.pe(e)\n",
        "        m = self.block1(e)\n",
        "        m = self.block2(m)\n",
        "        m = self.block3(m)\n",
        "        m = self.block4(m)\n",
        "        m = self.block5(m)\n",
        "        m = self.block6(m)\n",
        "        m = self.block7(m)\n",
        "        m = self.block8(m)\n",
        "        return self.f_lin(self.drop(m))"
      ],
      "metadata": {
        "id": "nNn0nePkYYEU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class LiGO(torch.nn.Module):\n",
        "    def __init__(self, width=False) -> None:\n",
        "        super(LiGO, self).__init__()\n",
        "        self.emb = FusedEmbedding(emb_params=model.embedding.weight.flatten().clone(), width=width, static=True, width_static=False)\n",
        "        self.pe = PositionalEncoding(d_model=new_emb_size if width else emb_size)\n",
        "        self.block1 = FusedBlock(width=width, width_static=False)\n",
        "        self.block2 = FusedBlock(width=width, width_static=False)\n",
        "        self.block3 = FusedBlock(width=width, width_static=False)\n",
        "        self.block4 = FusedBlock(width=width, width_static=False)\n",
        "        self.block5 = FusedBlock(width=width, width_static=False)\n",
        "        self.block6 = FusedBlock(width=width, width_static=False)\n",
        "        self.block7 = FusedBlock(width=width, width_static=False)\n",
        "        self.block8 = FusedBlock(width=width, width_static=False)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        self.f_lin = FusedLin(1, in_dim=emb_size if not width else new_emb_size, out_dim=vocab_size, static=True, small_params_w= model.f_lin.weight.flatten().clone(), small_params_b=model.f_lin.bias.clone(), width=width, old_in_dim=emb_size, old_out_dim=vocab_size)\n",
        "    def forward(self, inp):\n",
        "        e = self.emb(inp)\n",
        "        e = self.pe(e)\n",
        "        m = self.block1(e)\n",
        "        m = self.block2(m)\n",
        "        m = self.block3(m)\n",
        "        m = self.block4(m)\n",
        "        m = self.block5(m)\n",
        "        m = self.block6(m)\n",
        "        m = self.block7(m)\n",
        "        m = self.block8(m)\n",
        "        return self.f_lin(self.drop(m))"
      ],
      "metadata": {
        "id": "krOOdL0dYltH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossLiGO(torch.nn.Module):\n",
        "    def __init__(self, width=False) -> None:\n",
        "        super(CrossLiGO, self).__init__()\n",
        "        self.emb = FusedEmbedding(emb_params=model.embedding.weight.flatten().detach().clone(), width=width, static=True, width_static=False)\n",
        "        self.pe = PositionalEncoding(d_model=new_emb_size if width else emb_size)\n",
        "        self.block1 = FusedBlock(static=True, layerNum=0, width=width)\n",
        "        self.block3 = FusedBlock(static=True, layerNum=1, width=width)\n",
        "        self.block5 = FusedBlock(static=True, layerNum=2, width=width)\n",
        "        self.block7 = FusedBlock(static=True, layerNum=3, width=width)\n",
        "        self.block2 = FusedBlock(width=width, width_static=False)\n",
        "        self.block4 = FusedBlock(width=width, width_static=False)\n",
        "        self.block6 = FusedBlock(width=width, width_static=False)\n",
        "        self.block8 = FusedBlock(width=width, width_static=False)\n",
        "        self.drop = torch.nn.Dropout(0.1)\n",
        "        self.f_lin = FusedLin(1, in_dim=emb_size if not width else new_emb_size, out_dim=vocab_size, static=True, small_params_w= model.f_lin.weight.flatten().clone().to(device), small_params_b=model.f_lin.bias.detach().clone().to(device), width=width, old_in_dim=emb_size, old_out_dim=vocab_size)\n",
        "    def forward(self, inp):\n",
        "        e = self.emb(inp)\n",
        "        e = self.pe(e)\n",
        "        m = self.block1(e)\n",
        "        m = self.block2(m)\n",
        "        m = self.block3(m)\n",
        "        m = self.block4(m)\n",
        "        m = self.block5(m)\n",
        "        m = self.block6(m)\n",
        "        m = self.block7(m)\n",
        "        m = self.block8(m)\n",
        "        return self.f_lin(self.drop(m))\n"
      ],
      "metadata": {
        "id": "on9ExGgpYmDE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def initLiGO(stackLiGO, bigModel):\n",
        "    # Embedding layer\n",
        "    emb = stackLiGO.emb.emb_params\n",
        "    if stackLiGO.emb.width and not stackLiGO.emb.width_static:\n",
        "        emb = stackLiGO.emb.width_w(emb)\n",
        "    setattr(bigModel.embedding, 'weight', torch.nn.Parameter(emb, requires_grad=True).to(device))\n",
        "    # Final Linear layer\n",
        "    f_lin_w = stackLiGO.f_lin.small_params_w.view(vocab_size, -1)\n",
        "    f_lin_b = stackLiGO.f_lin.small_params_b\n",
        "    if stackLiGO.f_lin.width:\n",
        "        f_lin_w = (stackLiGO.f_lin.width_wb(f_lin_w))\n",
        "        # f_lin_w = (stackLiGO.f_lin.width_wa(f_lin_w.T)).T     Issues with big vocab size\n",
        "        # f_lin_b = stackLiGO.f_lin.width_b.weight@f_lin_b\n",
        "    setattr(bigModel.f_lin, 'weight', torch.nn.Parameter(f_lin_w.view(vocab_size, -1), requires_grad=True).to(device))\n",
        "    setattr(bigModel.f_lin, 'bias', torch.nn.Parameter(f_lin_b, requires_grad=True).to(device))\n",
        "    num_layers = num_large_layers if type(stackLiGO) is not LiGO_W else num_small_layers\n",
        "    for i in range(1, num_layers+1):\n",
        "        fused_block = getattr(stackLiGO, f'block{i}')\n",
        "        big_block = getattr(bigModel, f'block{i}')\n",
        "        # Setting FFN Weights\n",
        "        if fused_block.ffn.static:\n",
        "            if fused_block.ffn.width:\n",
        "                if fused_block.ffn.width_static:\n",
        "                    fb_w = fused_block.ffn.small_params_w.view(new_emb_size, new_emb_size)\n",
        "                    fb_b = fused_block.ffn.small_params_b\n",
        "                else:\n",
        "                    fb_w = fused_block.ffn.small_params_w.view(emb_size, emb_size)\n",
        "                    fb_b = fused_block.ffn.small_params_b\n",
        "                    fb_w = fused_block.ffn.width_wb(fb_w)\n",
        "                    fb_w = fused_block.ffn.width_wa(fb_w.T).T\n",
        "                    fb_b = fused_block.ffn.width_b.weight@fb_b\n",
        "            else:\n",
        "                fb_w = fused_block.ffn.small_params_w.view(emb_size, emb_size)\n",
        "                fb_b = fused_block.ffn.small_params_b\n",
        "        else:\n",
        "            fb_w = (ffn_w_params.T@fused_block.ffn.lin_w).view(emb_size, emb_size)\n",
        "            fb_b = (ffn_b_params.T@fused_block.ffn.lin_b)\n",
        "            if fused_block.ffn.width:\n",
        "                fb_w = fused_block.ffn.width_wb(fb_w)\n",
        "                fb_w = fused_block.ffn.width_wa(fb_w.T).T\n",
        "                fb_b = fused_block.ffn.width_b.weight@fb_b\n",
        "        setattr(big_block.ffn, 'weight', torch.nn.Parameter(fb_w, requires_grad=True).to(device))\n",
        "        setattr(big_block.ffn, 'bias', torch.nn.Parameter(fb_b, requires_grad=True).to(device))\n",
        "        # Setting Norm Layers\n",
        "        if fused_block.static:\n",
        "            n_w_1 = fused_block.norm_1.small_params_w\n",
        "            n_b_1 = fused_block.norm_1.small_params_b\n",
        "            n_w_2 = fused_block.norm_2.small_params_w\n",
        "            n_b_2 = fused_block.norm_2.small_params_b\n",
        "            if not fused_block.width_static:\n",
        "                n_w_1 = fused_block.norm_1.width_w.weight@n_w_1\n",
        "                n_b_1 = fused_block.norm_1.width_b.weight@n_b_1\n",
        "                n_w_2 = fused_block.norm_2.width_w.weight@n_w_2\n",
        "                n_b_2 = fused_block.norm_2.width_b.weight@n_b_2\n",
        "        else:\n",
        "            n_w_1 = (l_norm_w_params.T@fused_block.norm_1.lin_w)\n",
        "            n_b_1 = (l_norm_b_params.T@fused_block.norm_1.lin_b)\n",
        "            n_w_2 = (l_norm_w_params.T@fused_block.norm_2.lin_w)\n",
        "            n_b_2 = (l_norm_b_params.T@fused_block.norm_2.lin_b)\n",
        "            if fused_block.norm_1.width:\n",
        "                n_w_1 = fused_block.norm_1.width_w.weight@n_w_1\n",
        "                n_b_1 = fused_block.norm_1.width_b.weight@n_b_1\n",
        "                n_w_2 = fused_block.norm_2.width_w.weight@n_w_2\n",
        "                n_b_2 = fused_block.norm_2.width_b.weight@n_b_2\n",
        "        setattr(big_block.l_norm_1, 'weight', torch.nn.Parameter(n_w_1, requires_grad=True).to(device))\n",
        "        setattr(big_block.l_norm_1, 'bias', torch.nn.Parameter(n_b_1, requires_grad=True).to(device))\n",
        "        setattr(big_block.l_norm_2, 'weight', torch.nn.Parameter(n_w_2, requires_grad=True).to(device))\n",
        "        setattr(big_block.l_norm_2, 'bias', torch.nn.Parameter(n_b_2, requires_grad=True).to(device))\n",
        "        # Setting Multi-Head Attention\n",
        "        if fused_block.static:\n",
        "            mh = fused_block.multiHead.mh_lin.small_params_w\n",
        "            if not fused_block.width_static:\n",
        "                mh = fused_block.multiHead.mh_lin.width_wb(mh.view(emb_size, multi_heads*emb_size))\n",
        "                mh = fused_block.multiHead.mh_lin.width_wa(mh.T).T\n",
        "        else:\n",
        "            mh = (lin_params.T@fused_block.multiHead.mh_lin.lin_w).view(emb_size, emb_size*multi_heads)\n",
        "            if fused_block.multiHead.mh_lin.width:\n",
        "                mh = fused_block.multiHead.mh_lin.width_wb(mh)\n",
        "                mh = fused_block.multiHead.mh_lin.width_wa(mh.T).T\n",
        "        setattr(big_block.multihead.mh_lin, 'weight', torch.nn.Parameter(mh, requires_grad=True))\n",
        "        for h in range(1, multi_heads+1):\n",
        "            head = getattr(big_block.multihead, f'head{h}')\n",
        "            fused_head = getattr(fused_block.multiHead, f'head{h}')\n",
        "            if fused_head.static:\n",
        "                k = fused_head.k.small_params_w\n",
        "                q = fused_head.q.small_params_w\n",
        "                v = fused_head.v.small_params_w\n",
        "                if not fused_block.width_static:\n",
        "                    k = fused_head.k.width_wb(k.view(emb_size, emb_size))\n",
        "                    k = fused_head.k.width_wa(k.T).T\n",
        "                    q = fused_head.q.width_wb(q.view(emb_size, emb_size))\n",
        "                    q = fused_head.q.width_wa(q.T).T\n",
        "                    v = fused_head.v.width_wb(v.view(emb_size, emb_size))\n",
        "                    v = fused_head.v.width_wa(v.T).T\n",
        "            else:\n",
        "                k = (k_params.T@fused_head.k.lin_w).view(emb_size, emb_size)\n",
        "                q = (q_params.T@fused_head.q.lin_w).view(emb_size, emb_size)\n",
        "                v = (v_params.T@fused_head.v.lin_w).view(emb_size, emb_size)\n",
        "                if fused_head.k.width:\n",
        "                    k = fused_head.k.width_wb(k)\n",
        "                    k = fused_head.k.width_wa(k.T).T\n",
        "                    q = fused_head.q.width_wb(q)\n",
        "                    q = fused_head.q.width_wa(q.T).T\n",
        "                    v = fused_head.v.width_wb(v)\n",
        "                    v = fused_head.v.width_wa(v.T).T\n",
        "            setattr(head.k, 'weight', torch.nn.Parameter(k, requires_grad=True).to(device))\n",
        "            setattr(head.q, 'weight', torch.nn.Parameter(q, requires_grad=True).to(device))\n",
        "            setattr(head.v, 'weight', torch.nn.Parameter(v, requires_grad=True).to(device))"
      ],
      "metadata": {
        "id": "t62NbCv-YutJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparative study models"
      ],
      "metadata": {
        "id": "LNpXXafVQaay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacking"
      ],
      "metadata": {
        "id": "0bdVtjg8QlZx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gMdeziLXZKB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LiGO Depth only"
      ],
      "metadata": {
        "id": "zjZRUsQiQnDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LiGO_d = LiGO(width=False).to(device)\n",
        "optim_ld = torch.optim.Adam(params=LiGO_d.parameters(), lr=1e-2)\n",
        "_=train(LiGO_d, optim_ld, 5)"
      ],
      "metadata": {
        "id": "4siD0J6ZXZgn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bigModel = BigModel(big=False).to(device)\n",
        "initLiGO(LiGO_d, bigModel)\n",
        "optim_b = torch.optim.Adam(params=bigModel.parameters(), lr=1e-3)\n",
        "ligo_depth_metrics = train(bigModel, optim_b, 20)"
      ],
      "metadata": {
        "id": "teo2n38rZLjL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrossLiGO depth only"
      ],
      "metadata": {
        "id": "Y6D__AgwRmTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl_d = CrossLiGO(width=False).to(device)\n",
        "optim_ldw = torch.optim.Adam(cl_d.parameters(), lr=1e-2)\n",
        "_=train(cl_d, optim_ldw, 5)"
      ],
      "metadata": {
        "id": "7LVmrSTVXZ_q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bigModel = BigModel(big=False).to(device)\n",
        "initLiGO(cl_d, bigModel)\n",
        "optim_b = torch.optim.Adam(params=bigModel.parameters(), lr=1e-3)\n",
        "cl_depth_metrics = train(bigModel, optim_b, 20, device=device)"
      ],
      "metadata": {
        "id": "II9AQuF1ZBuN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StackLiGO depth only"
      ],
      "metadata": {
        "id": "V086wHTJRqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stackLiGOd = StackLiGO(width=False).to(device)\n",
        "optim_sld = torch.optim.Adam(params=stackLiGOd.parameters(), lr=1e-2)\n",
        "_=train(stackLiGOd, optim_sld, 5)"
      ],
      "metadata": {
        "id": "dHnedDmgQgeQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bigModel = BigModel(big=False).to(device)\n",
        "initLiGO(stackLiGOd, bigModel)\n",
        "optim_b = torch.optim.Adam(params=bigModel.parameters(), lr=1e-3)\n",
        "sl_depth_metrics = train(bigModel, optim_b, 20)"
      ],
      "metadata": {
        "id": "Sww1G9PnZT03"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When to Grow Policy"
      ],
      "metadata": {
        "id": "yQA9otTCtHHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [3, 9, 18, 24, 30]"
      ],
      "metadata": {
        "id": "L-OhJJVRuFyI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Periodic Growth"
      ],
      "metadata": {
        "id": "PjDDUFq-tV7g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vF044bKjtMG3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convergence Growth"
      ],
      "metadata": {
        "id": "yD0aNGY4tY2r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwcGJbxMtatK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LipGrow Method"
      ],
      "metadata": {
        "id": "UJX8nFC6tbQR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5w5BuohftduI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ORL FRAWGrow Policy"
      ],
      "metadata": {
        "id": "zgzoag-OteHT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XyqoQftDtg-f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Growth Order"
      ],
      "metadata": {
        "id": "d_B9Rn-6togO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appending"
      ],
      "metadata": {
        "id": "_vLDDMXLtrJA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beLZyxo5tqCd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inserting in start"
      ],
      "metadata": {
        "id": "-3TBx3Bdtsvt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ttUIqHbztuzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RRS"
      ],
      "metadata": {
        "id": "RaeFuSNbtvei"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FTGwejVtxE9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "1c8bJcPOtzwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## α - learning rate"
      ],
      "metadata": {
        "id": "IWlURtsJt2k5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAwAP2_nt1X8"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}